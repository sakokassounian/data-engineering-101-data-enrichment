{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-campbell",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Engineering 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-consistency",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-senegal",
   "metadata": {},
   "source": [
    "One of the many things that data scientists really dislike is seeing missing, incomplete, or messy data, especially when it's filled with errors entered by humans. It makes their lives harder than they should be. Luckily, as the Python community grows, so do its tools to address these issues.\n",
    "\n",
    "In this article, I will show you some of the steps that I usually take before implementing EDA (exploratory data analysis) and how to ensure your database is ready for the next stage. The world of data engineering is much bigger in terms of the tools being used to implement such analyses, but most data engineers deal with this stuff on a daily basis.\n",
    "\n",
    "As a data analyst or scientist, remember that the lack of completeness and format errors can skew your results, as they may go undetected until a later stage. If you are into reporting, your aggregates and reports will suffer, especially if you're unable to easily track down bugs that may appear during the data preparation process. Instead of simply dropping columns and taking the clean data, we can take a few minutes to perform some health and completeness checks, which can mitigate a lot of problems. Think of it as a general health check when you visit your general practitioner or family doctor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-canberra",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-diversity",
   "metadata": {},
   "source": [
    "The data that will be presented today is a simulation of a university student database. It includes information from the human resources office, the medical center, and the educational board. Imagine that you are a data scientist working for the president's office who has asked you to create a report about the students in the science faculty who will be candidates for becoming astronauts and to be nominated for NASA.\n",
    "\n",
    "These students have undergone IQ/theoretical tests and physical exams. You have data from the three aforementioned faculties. The report should include the following information:\n",
    "\n",
    " - Student identifier\n",
    " - Name and last name of the student\n",
    " - Age of the student\n",
    " - Educational major\n",
    " - Academic seniority (which year the student is in)\n",
    " - Gender\n",
    " - Blood type\n",
    " - Grades of the physical exam\n",
    " - Grades of the theoretical/IQ exam\n",
    "\n",
    "You are supplied with three databases: the medical, theoretical, and physical education exams.\n",
    "\n",
    "\n",
    "#### <u>A. Medical information:  *med.csv*</u>\n",
    "~~~~\n",
    "The medical database only contains passport IDs and some student health information, as students first visit the medical center before registering in the HR system. They provide their passport number, later to be able to identify them or cross-check with the Ministry of Health. Some of the data is then sent to the HR system, where student profiles are created in the database. However, the medical data is not sent to HR due to the processing regulations of the university and the consent of the students. This includes medical private data. Blood types and donor information are useful for emergencies. The HR office is open 24/7, but the medical center is not equipped with full hospitalization equipment. Only special personnel can access health data\n",
    "~~~~\n",
    "\n",
    "\n",
    "\n",
    "#### <u>B. Physical education exam:</u> *field_exam*\n",
    "~~~~\n",
    "For the astronaut contest, before the physical exercise exam, the physical test experts ask candidate students for their passport IDs and request them to agree to grant access to and process the medical records from the medical center. Additionally, the students are asked to provide their student ID so that their grades can be downloaded to the grading system.\n",
    "~~~~\n",
    "\n",
    "\n",
    "#### <u>C. Theoretical exam:</u> *theory_exam.csv*\n",
    "~~~~\n",
    "The students will also take theoretical and IQ tests, and the test experts will send grades to a centralized grading system. These grades include student IDs, names, scores, and educational information about the student and their seniority.\n",
    "~~~~\n",
    "\n",
    "\n",
    "#### <u>D. Tuition fee transactions:</u> *tuition_fees.csv*\n",
    "~~~~\n",
    "The another table is an external table from the student affairs office of the university. Students pay there tuitions on-line. And the university's bank send the transactions fees based on the student ID. The Student's office affair is not allowed to see the personal information of the student. Only the ID to make sure the database is complete. If a student wants into ask about the status of the tuition or any other financial details, they have to supply their student ID at the front desk and they can cross check with the history. This report is going to the president of the university, he want to know the social status and financial situation of the students. We will find out by seeing who is on scholarship, who has loans, and who is paying the fees directly.       \n",
    "~~~~\n",
    "\n",
    "\n",
    "#### <u> E. Human Resources:</u> *HR.csv*\n",
    "~~~~\n",
    "As a data expert, you are allowed to communicate with the people who provided the data, whether it is for corrections, improvement of the data, or enrichment of the data .As you are the data expert in the president's office, you are allowed to process data only for this specific exercise. You can't access sensitive student data. For example, we have addresses of the students and additional health information, but only what is supplied to you.\n",
    "\n",
    "However, we can ask them to send us missing pieces of information if needed, to correct or enhance our results.\n",
    "\n",
    "~~~~\n",
    "\n",
    "#### <u> F. The simulation</u>:  *main.csv*\n",
    "~~~~\n",
    "This is the file where I created and simulated the data for this exercise. There are extra columns where you can experiment with and create your own data scenarios\n",
    "~~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-fitness",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## The code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-calibration",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "acute-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from dateutil import parser as date_parser\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "from fuzzywuzzy import process as fw_process\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "timely-instrument",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re==2.2.1\n",
      "dateutil==2.8.2\n",
      "numpy==1.26.3\n",
      "pandas==2.1.1\n",
      "fuzzywuzzy==0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Get a dictionary of all loaded modules\n",
    "loaded_modules = sys.modules\n",
    "\n",
    "\n",
    "# Print the name and version of each loaded module\n",
    "libraries = ['os','pandas','dateutil','re','numpy','sys','fuzzywuzzy','datetime']\n",
    "for module_name, module in loaded_modules.items():\n",
    "    if module_name in libraries:\n",
    "        if hasattr(module, \"__version__\"):\n",
    "            print(f\"{module_name}=={module.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-fight",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Storing the data into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-indicator",
   "metadata": {},
   "source": [
    "One of the things I like to do as a data scientist when working on proof-of-concept projects is to experiment with code where the data is stored in its original shape. Typically, I extract small chunks of data to play with in a test environment. This allows me to work with data that has a small size and doesn't consume too much memory. Additionally, it speeds up the execution of codes and enables quick A/B tests. All of this without having to rewrite the same dataframe, using it as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "romance-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store them in a dict \n",
    "database = {  }\n",
    "database['HR']  = pd.read_csv(\"fixtures/HR.csv\")\n",
    "database['MEDICAL']  = pd.read_csv(\"fixtures/medical.csv\")\n",
    "database['PE_EXAM']  = pd.read_csv(\"fixtures/field_exam.csv\")\n",
    "database['THEO_EXAM']  =pd.read_csv(\"fixtures/theory_exam.csv\")\n",
    "database['FEES']  =pd.read_csv(\"fixtures/tuition_fees.csv\")\n",
    "database['MAIN']  =pd.read_csv(\"fixtures/main.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-native",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### The text cleaning function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-hawaii",
   "metadata": {},
   "source": [
    "It's here where all the magic starts. Below you will see 2 functions\n",
    "**text_cleaner**: This function is intended to fix the headers of a database. Let's say you got you data as an excel. A human being has messed up with it, added very weird characters which makes it harder to use and store. \n",
    "\n",
    "So it removes all the special characters and replaces them with an underscore or any value need. It makes it lowercase. It also replaces digits with characters that resemble the digit. For example 5 is replaced with an \"S\"\n",
    "\n",
    "You can also pass a list of strings and it will replace them with that value before removing all the special characters. Check the function below you'll also see some example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "complicated-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(val_str, \n",
    "                        pre_replacements = None,\n",
    "                        digit_replacement = True,\n",
    "                        character_replacer=\"_\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will clean the strings and replace them with a standardized\n",
    "    form.  We will remove punctuation. Large spaces replaced witha a single underscore. \n",
    "    Digits will be replace other resembling letters. Finally everything will be lower cased. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_str : string\n",
    "        The string to be cleaned\n",
    "    custom_replacements: string\n",
    "        This is usually a list of string you want to replace with an \"_\" before removing them. \n",
    "        \n",
    "       \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    val_str_clean: list of string.\n",
    "        The final cleaned string\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    val_str_clean = val_str\n",
    "    \n",
    "    if pre_replacements:\n",
    "        val_str_clean =  val_str_clean.translate({ord(i): character_replacer for i in pre_replacements})\n",
    "\n",
    "    \n",
    "    # I got this from yje package \"string\". The underscore was removed\n",
    "    punct = '!\"#$%&\\'()*+,-–./:;<=>?@[\\\\]^`{|}~_'.replace(character_replacer,\"\")\n",
    "    digits = '0123456789'\n",
    "    \n",
    "    # Remove all the special characters and the spaces at the begining and end\n",
    "    val_str_clean = val_str_clean.translate({ord(i): \"\" for i in punct}).lstrip().rstrip().lower()\n",
    "    \n",
    "    \n",
    "    # Replace spaces with \"_\"\n",
    "    val_str_clean = re.sub(\"\\s+\",character_replacer,val_str_clean)\n",
    "    \n",
    "    # replace digits with special characters\n",
    "    morphological_letters = {\n",
    "    '0': 'O',\n",
    "    '1': 'I',\n",
    "    '2': 'Z',\n",
    "    '3': 'E',\n",
    "    '4': 'A',\n",
    "    '5': 'S',\n",
    "    '6': 'G',\n",
    "    '7': 'T',\n",
    "    '8': 'B',\n",
    "    '9': 'g'}\n",
    "    \n",
    "    if digit_replacement:        \n",
    "        # Remove all the special characters and the spaces at the begining and end\n",
    "        val_str_clean = val_str_clean.translate({ord(i): morphological_letters[i] for i in digits})\n",
    "        \n",
    "        \n",
    "    return val_str_clean \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "continent-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s_ud_ents__GSEgBE'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner(\" s.ud_ents. !65/*/*/3983\",pre_replacements = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "sticky-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stud-ents-653983sss'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not that strings are iterable so whether you pass [\"1\",\"2\",\"3\"] or \"123\" it's the same\n",
    "text_cleaner(\" stud@en#ts. !65/*/*/3983sss\",\n",
    "                 digit_replacement = False,\n",
    "                 character_replacer='-',\n",
    "                 pre_replacements = \"@\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-liver",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### The dataframe optimizing function\n",
    "\n",
    "Below is our main cleaning function; *optimize_dataframe*. It will do a few things: \n",
    "\n",
    "1. It will convert the pandas dataframe into an optimized data format per columns. I use the built in function called [convert_dtype](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.convert_dtypes.html). This function is really useful since it minimizes the memory consumption and convert strings which are completely integer into their natural types. \n",
    "2. Tries to figure out if a column is a date or a numeric and tries to parse it.  \n",
    "3. Stores the datatypes in a summary dictionary with both old and new column naming\n",
    "4. Uses the *text_cleaner* function to rename the columns and edit the date column format to make it in a format that can be parsed. \n",
    "5. Returns a dictionary that has the cleaned dataframe and it's meta data describing the column rename and data types.  \n",
    "6. It creates unique IDs that can be easily sorted and names by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "narrow-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dataframe(df, \n",
    "                        pre_clean_str='.',\n",
    "                        date_delimter='-',\n",
    "                        id_prefix=\"\",\n",
    "                        id_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    This function cleans a database to it's optimal datatype and tries to\n",
    "    parse dates. You can retrun the metadata or simply the clean dataframe. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        The dataframe to be cleaned.\n",
    "    pre_clean_str : str, optional\n",
    "        A string that contains different character. If you want to do a pre-clean\n",
    "        to replace specific characters with and \"_\". The process of the cleaning\n",
    "        is based on removing all the special characters. \n",
    "        Example: \"NAME.first\" becomes \"namefirst\", but if you keep the value\n",
    "        to \".\", it becomes \"name_first\". The default is '.'.\n",
    "\n",
    "    date_delimter : str, optional\n",
    "        This value is replaced with the special characters if the columns types\n",
    "        is detected to be a date. This improves the date parsing. The default is '-'.\n",
    "    id_prefix : str, optional\n",
    "        Add a prefix to the ID column values. The default is \"\".\n",
    "    id_suffix : TYPE, optional\n",
    "        Add a suffix to the ID column valies. The default is \"\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Contains the database and its metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    convertion_types = ['bytes',\n",
    "                     'floating',\n",
    "                     'integer',\n",
    "                     'mixed-integer',\n",
    "                     'mixed-integer-float',\n",
    "                     'decimal',\n",
    "                     'complex',\n",
    "                     'categorical',\n",
    "                     'boolean',\n",
    "                     'datetime64',\n",
    "                     'datetime',\n",
    "                     'date',\n",
    "                     'timedelta64',\n",
    "                     'timedelta',\n",
    "                     'time',\n",
    "                     'period',\n",
    "                     'mixed']\n",
    "    \n",
    "\n",
    "    df_use = df.copy().convert_dtypes()\n",
    "    \n",
    "    \n",
    "    # Now we will analyze the data     \n",
    "    database_meta = {'col_name':[],'clean_col_name':[],\"col_type\":[],\"original_col_type\":[]} \n",
    "    for col_name,col_type in df_use.dtypes.astype(str).to_dict().items():\n",
    "        \n",
    "        optimal_type = col_type\n",
    "        \n",
    "        if optimal_type =='string':\n",
    "            \n",
    "            # Maybe it's mixed of numbers and strings \n",
    "            col_temp = pd.Series(df_use[col_name].unique())\n",
    "            col_temp = col_temp.apply(pd.to_numeric,errors='coerce').fillna(col_temp)\n",
    "            \n",
    "            # Extract after convertig numerical\n",
    "            analysis_type = pd.api.types.infer_dtype(col_temp)\n",
    "            \n",
    "            # This activates if the type changes\n",
    "            if analysis_type in convertion_types: \n",
    "                optimal_type = analysis_type\n",
    "                \n",
    "            else: \n",
    "                try:\n",
    "                    # Let's parse dates\n",
    "                    df_use[col_name].dropna().sample(10).\\\n",
    "                            apply(lambda x : text_cleaner(x,\n",
    "                                                          digit_replacement=False,     \n",
    "                                                          character_replacer=date_delimter)).apply(date_parser.parse)   \n",
    "                    optimal_type = 'datetime'\n",
    "                    \n",
    "                except: \n",
    "                    pass\n",
    "        \n",
    "        # store the information\n",
    "        database_meta['original_col_type'].append(str(df[col_name].dtypes))\n",
    "        database_meta['col_type'].append(optimal_type)\n",
    "        database_meta[\"col_name\"].append(col_name)\n",
    "        database_meta[\"clean_col_name\"].append(text_cleaner(col_name,pre_replacements=pre_clean_str))\n",
    "    \n",
    "    # now we will convert the datetypes into date format    \n",
    "    \"\"\"If there is format error, we'll be able to detect it here\"\"\"\n",
    "    for col_name,col_type in zip(database_meta['col_name'],database_meta['col_type']):\n",
    "        if col_type =='datetime':\n",
    "            df_use[col_name] = df_use[col_name].apply(lambda x : text_cleaner(x,\n",
    "                                                    digit_replacement=False,     \n",
    "                                                    character_replacer=date_delimter)).apply(date_parser.parse)  \n",
    "    \n",
    "    \n",
    "            \n",
    "    # Rename database: As the renaming is the last step duplicate columns will not cause issues.\n",
    "    df_use = df_use.rename({i:j for i,j in zip(database_meta[\"col_name\"],database_meta[\"clean_col_name\"])},axis=1)        \n",
    "    \n",
    "    \n",
    "    # Add unique id\n",
    "    if id_prefix: id_prefix = id_prefix+\"_\"\n",
    "    if id_suffix: id_prefix = \"_\"+id_suffix\n",
    "    \n",
    "    \n",
    "    max_num = df_use.shape[0]\n",
    "    max_digit_size = len(str(max_num))\n",
    "    number_list = [str(num).zfill(max_digit_size) for num in range(1, max_num+1)]\n",
    "    df_use['db_ID'] = [f\"{id_prefix}{i}{id_suffix}\" for i in number_list]\n",
    "        \n",
    "    \n",
    "\n",
    "    return  {\"db\":df_use, \"metadata\": database_meta}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "instrumental-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>clean_col_name</th>\n",
       "      <th>col_type</th>\n",
       "      <th>original_col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enrollment date</td>\n",
       "      <td>enrollment_date</td>\n",
       "      <td>datetime</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date of Birth</td>\n",
       "      <td>date_of_birth</td>\n",
       "      <td>datetime</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passport id</td>\n",
       "      <td>passport_id</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student.ID</td>\n",
       "      <td>student_id</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Student.First Name</td>\n",
       "      <td>student_first_name</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Student.Last Name</td>\n",
       "      <td>student_last_name</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Address – lat</td>\n",
       "      <td>address_lat</td>\n",
       "      <td>Float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Address ! Long</td>\n",
       "      <td>address_long</td>\n",
       "      <td>Float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Morale %</td>\n",
       "      <td>morale</td>\n",
       "      <td>Float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>unnamed_IO</td>\n",
       "      <td>Int64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>unnamed_II</td>\n",
       "      <td>Int64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unnamed: 12</td>\n",
       "      <td>unnamed_IZ</td>\n",
       "      <td>Int64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>student GPA ( letter )</td>\n",
       "      <td>student_gpa_letter</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Field exam score</td>\n",
       "      <td>field_exam_score</td>\n",
       "      <td>Int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tution fee</td>\n",
       "      <td>tution_fee</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cafetria comments</td>\n",
       "      <td>cafetria_comments</td>\n",
       "      <td>mixed</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Seniortiy Description</td>\n",
       "      <td>seniortiy_description</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Major=</td>\n",
       "      <td>major</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Major!</td>\n",
       "      <td>major</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Blood type</td>\n",
       "      <td>blood_type</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gender</td>\n",
       "      <td>gender</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Organ Donor</td>\n",
       "      <td>organ_donor</td>\n",
       "      <td>boolean</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Blood Donor</td>\n",
       "      <td>blood_donor</td>\n",
       "      <td>Int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  col_name         clean_col_name  col_type original_col_type\n",
       "0          Enrollment date        enrollment_date  datetime            object\n",
       "1            Date of Birth          date_of_birth  datetime            object\n",
       "2              Passport id            passport_id    string            object\n",
       "3                    email                  email    string            object\n",
       "4               Student.ID             student_id    string            object\n",
       "5       Student.First Name     student_first_name    string            object\n",
       "6        Student.Last Name      student_last_name    string            object\n",
       "7           Address – lat             address_lat   Float64           float64\n",
       "8           Address ! Long           address_long   Float64           float64\n",
       "9                 Morale %                 morale   Float64           float64\n",
       "10             Unnamed: 10             unnamed_IO     Int64           float64\n",
       "11             Unnamed: 11             unnamed_II     Int64           float64\n",
       "12             Unnamed: 12             unnamed_IZ     Int64           float64\n",
       "13  student GPA ( letter )     student_gpa_letter    string            object\n",
       "14        Field exam score       field_exam_score     Int64             int64\n",
       "15             Tution fee              tution_fee    string            object\n",
       "16       Cafetria comments      cafetria_comments     mixed            object\n",
       "17   Seniortiy Description  seniortiy_description    string            object\n",
       "18                  Major=                  major    string            object\n",
       "19                  Major!                  major    string            object\n",
       "20              Blood type             blood_type    string            object\n",
       "21                  Gender                 gender    string            object\n",
       "22             Organ Donor            organ_donor   boolean              bool\n",
       "23             Blood Donor            blood_donor     Int64             int64"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will iterate over the databases and store it with it's key name\n",
    "clean_db = {i:optimize_dataframe(j,id_prefix=i) for i,j in database.items()}\n",
    "\n",
    "temp = pd.DataFrame(clean_db['MAIN']['metadata'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-affiliate",
   "metadata": {},
   "source": [
    "The previous databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "visible-complex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enrollment date</th>\n",
       "      <td>98</td>\n",
       "      <td>73</td>\n",
       "      <td>2015 | OCTOBER | 10</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Birth</th>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>03/07/93</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passport id</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>C161A7431</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>LyndiMuamir@sk.edu.pl</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student.ID</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student.First Name</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>Lyndi</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student.Last Name</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>Muamir</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Address – lat</th>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.378481</td>\n",
       "      <td>51.35186</td>\n",
       "      <td>-89.95953</td>\n",
       "      <td>-33.896191</td>\n",
       "      <td>9.860808</td>\n",
       "      <td>49.918262</td>\n",
       "      <td>84.336175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Address ! Long</th>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.663295</td>\n",
       "      <td>112.55217</td>\n",
       "      <td>-179.7813</td>\n",
       "      <td>-123.575638</td>\n",
       "      <td>-41.255485</td>\n",
       "      <td>83.88495</td>\n",
       "      <td>175.496775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morale %</th>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511082</td>\n",
       "      <td>0.252594</td>\n",
       "      <td>0.02915</td>\n",
       "      <td>0.314538</td>\n",
       "      <td>0.533621</td>\n",
       "      <td>0.713352</td>\n",
       "      <td>0.970296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student GPA ( letter )</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>A+</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field exam score</th>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.591837</td>\n",
       "      <td>28.953869</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>76.75</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tution fee</th>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>920 USD</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cafetria comments</th>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>Soup's warm, bread's soft, satisfying.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seniortiy Description</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major=</th>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major!</th>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood type</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>O+</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organ Donor</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood Donor</th>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.478443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique                                     top  \\\n",
       "Enrollment date           98     73                     2015 | OCTOBER | 10   \n",
       "Date of Birth             98     92                                03/07/93   \n",
       "Passport id               98     98                               C161A7431   \n",
       "email                     98     98                   LyndiMuamir@sk.edu.pl   \n",
       "Student.ID                98     98                              D34Q23Q41L   \n",
       "Student.First Name        98     98                                   Lyndi   \n",
       "Student.Last Name         98     98                                  Muamir   \n",
       "Address – lat           94.0    NaN                                     NaN   \n",
       "Address ! Long          94.0    NaN                                     NaN   \n",
       "Morale %                98.0    NaN                                     NaN   \n",
       "Unnamed: 10              0.0    NaN                                     NaN   \n",
       "Unnamed: 11              0.0    NaN                                     NaN   \n",
       "Unnamed: 12              0.0    NaN                                     NaN   \n",
       "student GPA ( letter )    98      8                                      A+   \n",
       "Field exam score        98.0    NaN                                     NaN   \n",
       "Tution fee                95     90                                 920 USD   \n",
       "Cafetria comments         96     63  Soup's warm, bread's soft, satisfying.   \n",
       "Seniortiy Description     98      3                                Freshman   \n",
       "Major=                    98     10                    Chemical Engineering   \n",
       "Major!                    98     10                    Chemical Engineering   \n",
       "Blood type                98      8                                      O+   \n",
       "Gender                    98      2                                  Female   \n",
       "Organ Donor               98      2                                   False   \n",
       "Blood Donor             98.0    NaN                                     NaN   \n",
       "\n",
       "                       freq       mean        std       min         25%  \\\n",
       "Enrollment date           6        NaN        NaN       NaN         NaN   \n",
       "Date of Birth             2        NaN        NaN       NaN         NaN   \n",
       "Passport id               1        NaN        NaN       NaN         NaN   \n",
       "email                     1        NaN        NaN       NaN         NaN   \n",
       "Student.ID                1        NaN        NaN       NaN         NaN   \n",
       "Student.First Name        1        NaN        NaN       NaN         NaN   \n",
       "Student.Last Name         1        NaN        NaN       NaN         NaN   \n",
       "Address – lat           NaN   6.378481   51.35186 -89.95953  -33.896191   \n",
       "Address ! Long          NaN -20.663295  112.55217 -179.7813 -123.575638   \n",
       "Morale %                NaN   0.511082   0.252594   0.02915    0.314538   \n",
       "Unnamed: 10             NaN        NaN        NaN       NaN         NaN   \n",
       "Unnamed: 11             NaN        NaN        NaN       NaN         NaN   \n",
       "Unnamed: 12             NaN        NaN        NaN       NaN         NaN   \n",
       "student GPA ( letter )   26        NaN        NaN       NaN         NaN   \n",
       "Field exam score        NaN  51.591837  28.953869       2.0        24.0   \n",
       "Tution fee                2        NaN        NaN       NaN         NaN   \n",
       "Cafetria comments         3        NaN        NaN       NaN         NaN   \n",
       "Seniortiy Description    39        NaN        NaN       NaN         NaN   \n",
       "Major=                   14        NaN        NaN       NaN         NaN   \n",
       "Major!                   14        NaN        NaN       NaN         NaN   \n",
       "Blood type               15        NaN        NaN       NaN         NaN   \n",
       "Gender                   52        NaN        NaN       NaN         NaN   \n",
       "Organ Donor              57        NaN        NaN       NaN         NaN   \n",
       "Blood Donor             NaN   0.653061   0.478443       0.0         0.0   \n",
       "\n",
       "                              50%        75%         max  \n",
       "Enrollment date               NaN        NaN         NaN  \n",
       "Date of Birth                 NaN        NaN         NaN  \n",
       "Passport id                   NaN        NaN         NaN  \n",
       "email                         NaN        NaN         NaN  \n",
       "Student.ID                    NaN        NaN         NaN  \n",
       "Student.First Name            NaN        NaN         NaN  \n",
       "Student.Last Name             NaN        NaN         NaN  \n",
       "Address – lat            9.860808  49.918262   84.336175  \n",
       "Address ! Long         -41.255485   83.88495  175.496775  \n",
       "Morale %                 0.533621   0.713352    0.970296  \n",
       "Unnamed: 10                   NaN        NaN         NaN  \n",
       "Unnamed: 11                   NaN        NaN         NaN  \n",
       "Unnamed: 12                   NaN        NaN         NaN  \n",
       "student GPA ( letter )        NaN        NaN         NaN  \n",
       "Field exam score             54.5      76.75       100.0  \n",
       "Tution fee                    NaN        NaN         NaN  \n",
       "Cafetria comments             NaN        NaN         NaN  \n",
       "Seniortiy Description         NaN        NaN         NaN  \n",
       "Major=                        NaN        NaN         NaN  \n",
       "Major!                        NaN        NaN         NaN  \n",
       "Blood type                    NaN        NaN         NaN  \n",
       "Gender                        NaN        NaN         NaN  \n",
       "Organ Donor                   NaN        NaN         NaN  \n",
       "Blood Donor                   1.0        1.0         1.0  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database['MAIN'].describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-coordinate",
   "metadata": {},
   "source": [
    "Be careful because some issues can arise. For example, take a look at the \"major\" column, they are now duplicated, or even some columns might be numeric but instead they are actually contains data and requires cleaning. Take a look at the **tution** column ... I kept the typo on purpose to show you even the column names can have problems ( I'm kidding! I discovered it at this phase it but kept it to show you my human error :D). \n",
    "\n",
    "So after you detect these issues it would be nice to clean them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "yellow-minority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      550 USD\n",
       "1      780 USD\n",
       "2     1879 USD\n",
       "3     1215 USD\n",
       "4      522 USD\n",
       "        ...   \n",
       "93    1850 USD\n",
       "94    1968 USD\n",
       "95    1364 USD\n",
       "96     666 USD\n",
       "97    1649 USD\n",
       "Name: tution_fee, Length: 98, dtype: string"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_db['MAIN']['db']['tution_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "judicial-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the tuition columns\n",
    "clean_db['MAIN']['db']['tution_fee'] = clean_db['MAIN']['db']['tution_fee'].map(lambda x: x.split(\"USD\")[0],na_action='ignore').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "mexican-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the empty columns\n",
    "clean_db['MAIN']['db'] = clean_db['MAIN']['db'].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "indirect-checklist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organ_donor</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seniortiy_description</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_gpa_letter</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>A+</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_type</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>O+</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafetria_comments</th>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>Soup's warm, bread's soft, satisfying.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passport_id</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>C195F5934</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>FriedlindSnævar@sk.edu.pl</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_id</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>N95K98P24K</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_first_name</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>Friedlind</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_last_name</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>Snævar</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_ID</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>MAIN_98</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enrollment_date</th>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-12 17:08:34.285714176</td>\n",
       "      <td>2012-10-02 00:00:00</td>\n",
       "      <td>2013-10-07 06:00:00</td>\n",
       "      <td>2014-10-04 00:00:00</td>\n",
       "      <td>2015-10-10 00:00:00</td>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_birth</th>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-04-23 20:48:58.775510144</td>\n",
       "      <td>1993-01-11 00:00:00</td>\n",
       "      <td>1993-08-21 18:00:00</td>\n",
       "      <td>1994-03-30 12:00:00</td>\n",
       "      <td>1994-12-07 18:00:00</td>\n",
       "      <td>1995-11-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address_lat</th>\n",
       "      <td>94.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.378481</td>\n",
       "      <td>-89.95953</td>\n",
       "      <td>-33.896191</td>\n",
       "      <td>9.860808</td>\n",
       "      <td>49.918262</td>\n",
       "      <td>84.336175</td>\n",
       "      <td>51.35186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address_long</th>\n",
       "      <td>94.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-20.663295</td>\n",
       "      <td>-179.7813</td>\n",
       "      <td>-123.575638</td>\n",
       "      <td>-41.255485</td>\n",
       "      <td>83.88495</td>\n",
       "      <td>175.496775</td>\n",
       "      <td>112.55217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morale</th>\n",
       "      <td>98.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.511082</td>\n",
       "      <td>0.02915</td>\n",
       "      <td>0.314538</td>\n",
       "      <td>0.533621</td>\n",
       "      <td>0.713352</td>\n",
       "      <td>0.970296</td>\n",
       "      <td>0.252594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field_exam_score</th>\n",
       "      <td>98.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>51.591837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>76.75</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.953869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tution_fee</th>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1208.265306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.75</td>\n",
       "      <td>1205.5</td>\n",
       "      <td>1606.5</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>483.347638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_donor</th>\n",
       "      <td>98.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count unique                                     top  \\\n",
       "gender                   98      2                                  Female   \n",
       "organ_donor              98      2                                   False   \n",
       "seniortiy_description    98      3                                Freshman   \n",
       "student_gpa_letter       98      8                                      A+   \n",
       "blood_type               98      8                                      O+   \n",
       "major                    98     10                    Chemical Engineering   \n",
       "major                    98     10                    Chemical Engineering   \n",
       "cafetria_comments        96     63  Soup's warm, bread's soft, satisfying.   \n",
       "passport_id              98     98                               C195F5934   \n",
       "email                    98     98               FriedlindSnævar@sk.edu.pl   \n",
       "student_id               98     98                              N95K98P24K   \n",
       "student_first_name       98     98                               Friedlind   \n",
       "student_last_name        98     98                                  Snævar   \n",
       "db_ID                    98     98                                 MAIN_98   \n",
       "enrollment_date          98    NaN                                     NaN   \n",
       "date_of_birth            98    NaN                                     NaN   \n",
       "address_lat            94.0   <NA>                                    <NA>   \n",
       "address_long           94.0   <NA>                                    <NA>   \n",
       "morale                 98.0   <NA>                                    <NA>   \n",
       "field_exam_score       98.0   <NA>                                    <NA>   \n",
       "tution_fee             98.0    NaN                                     NaN   \n",
       "blood_donor            98.0   <NA>                                    <NA>   \n",
       "\n",
       "                       freq                           mean  \\\n",
       "gender                   52                            NaN   \n",
       "organ_donor              57                            NaN   \n",
       "seniortiy_description    39                            NaN   \n",
       "student_gpa_letter       26                            NaN   \n",
       "blood_type               15                            NaN   \n",
       "major                    14                            NaN   \n",
       "major                    14                            NaN   \n",
       "cafetria_comments         3                            NaN   \n",
       "passport_id               1                            NaN   \n",
       "email                     1                            NaN   \n",
       "student_id                1                            NaN   \n",
       "student_first_name        1                            NaN   \n",
       "student_last_name         1                            NaN   \n",
       "db_ID                     1                            NaN   \n",
       "enrollment_date         NaN  2014-06-12 17:08:34.285714176   \n",
       "date_of_birth           NaN  1994-04-23 20:48:58.775510144   \n",
       "address_lat            <NA>                       6.378481   \n",
       "address_long           <NA>                     -20.663295   \n",
       "morale                 <NA>                       0.511082   \n",
       "field_exam_score       <NA>                      51.591837   \n",
       "tution_fee              NaN                    1208.265306   \n",
       "blood_donor            <NA>                       0.653061   \n",
       "\n",
       "                                       min                  25%  \\\n",
       "gender                                 NaN                  NaN   \n",
       "organ_donor                            NaN                  NaN   \n",
       "seniortiy_description                  NaN                  NaN   \n",
       "student_gpa_letter                     NaN                  NaN   \n",
       "blood_type                             NaN                  NaN   \n",
       "major                                  NaN                  NaN   \n",
       "major                                  NaN                  NaN   \n",
       "cafetria_comments                      NaN                  NaN   \n",
       "passport_id                            NaN                  NaN   \n",
       "email                                  NaN                  NaN   \n",
       "student_id                             NaN                  NaN   \n",
       "student_first_name                     NaN                  NaN   \n",
       "student_last_name                      NaN                  NaN   \n",
       "db_ID                                  NaN                  NaN   \n",
       "enrollment_date        2012-10-02 00:00:00  2013-10-07 06:00:00   \n",
       "date_of_birth          1993-01-11 00:00:00  1993-08-21 18:00:00   \n",
       "address_lat                      -89.95953           -33.896191   \n",
       "address_long                     -179.7813          -123.575638   \n",
       "morale                             0.02915             0.314538   \n",
       "field_exam_score                       2.0                 24.0   \n",
       "tution_fee                             0.0               879.75   \n",
       "blood_donor                            0.0                  0.0   \n",
       "\n",
       "                                       50%                  75%  \\\n",
       "gender                                 NaN                  NaN   \n",
       "organ_donor                            NaN                  NaN   \n",
       "seniortiy_description                  NaN                  NaN   \n",
       "student_gpa_letter                     NaN                  NaN   \n",
       "blood_type                             NaN                  NaN   \n",
       "major                                  NaN                  NaN   \n",
       "major                                  NaN                  NaN   \n",
       "cafetria_comments                      NaN                  NaN   \n",
       "passport_id                            NaN                  NaN   \n",
       "email                                  NaN                  NaN   \n",
       "student_id                             NaN                  NaN   \n",
       "student_first_name                     NaN                  NaN   \n",
       "student_last_name                      NaN                  NaN   \n",
       "db_ID                                  NaN                  NaN   \n",
       "enrollment_date        2014-10-04 00:00:00  2015-10-10 00:00:00   \n",
       "date_of_birth          1994-03-30 12:00:00  1994-12-07 18:00:00   \n",
       "address_lat                       9.860808            49.918262   \n",
       "address_long                    -41.255485             83.88495   \n",
       "morale                            0.533621             0.713352   \n",
       "field_exam_score                      54.5                76.75   \n",
       "tution_fee                          1205.5               1606.5   \n",
       "blood_donor                            1.0                  1.0   \n",
       "\n",
       "                                       max         std  \n",
       "gender                                 NaN         NaN  \n",
       "organ_donor                            NaN         NaN  \n",
       "seniortiy_description                  NaN         NaN  \n",
       "student_gpa_letter                     NaN         NaN  \n",
       "blood_type                             NaN         NaN  \n",
       "major                                  NaN         NaN  \n",
       "major                                  NaN         NaN  \n",
       "cafetria_comments                      NaN         NaN  \n",
       "passport_id                            NaN         NaN  \n",
       "email                                  NaN         NaN  \n",
       "student_id                             NaN         NaN  \n",
       "student_first_name                     NaN         NaN  \n",
       "student_last_name                      NaN         NaN  \n",
       "db_ID                                  NaN         NaN  \n",
       "enrollment_date        2015-10-25 00:00:00         NaN  \n",
       "date_of_birth          1995-11-28 00:00:00         NaN  \n",
       "address_lat                      84.336175    51.35186  \n",
       "address_long                    175.496775   112.55217  \n",
       "morale                            0.970296    0.252594  \n",
       "field_exam_score                     100.0   28.953869  \n",
       "tution_fee                          1999.0  483.347638  \n",
       "blood_donor                            1.0    0.478443  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_db['MAIN']['db'].describe(include='all').T.sort_values(\"unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-reducing",
   "metadata": {},
   "source": [
    "You can see that now we converted it into numbers, ooh ... Look, we have 4 missing addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-image",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis of mergers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-payroll",
   "metadata": {},
   "source": [
    "When humans enter data manually into a simple database (let's say like an excel or website), common errors can include typos, formatting inconsistencies, missing data, incorrect calculations, or accidental deletion of important information. \n",
    "\n",
    "It gets even worse when multiple people are editing the same databases simultaneously or seperately, and the results is the having a non-standardazied database (which was the issues we tried to analyze earlier).These errors can lead to inaccurate analyses, flawed decision-making, and inefficiencies in data processing. \n",
    "\n",
    "To mitigate these issues, it's essential to implement data validation rules, utilize cell protection features, maintain clear documentation, establish version control protocols, provide training on data entry best practices, and regularly review and audit the data for accuracy.\n",
    "\n",
    "Below we will do an exercise on to see what are the effects of such errors specifically when doing table joins and how we can implement the best practices.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-stevens",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Sample merger \n",
    "\n",
    "Let's take a look at some our data individually and see what happens when we merge some tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "homeless-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some variables to store our tables \n",
    "df_hr   = clean_db['HR']['db'].copy()\n",
    "df_med  = clean_db['MEDICAL']['db'].copy()\n",
    "df_pe   = clean_db['PE_EXAM']['db'].copy()\n",
    "df_theo = clean_db['THEO_EXAM']['db'].copy()\n",
    "df_fee  = clean_db['FEES']['db'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-harvey",
   "metadata": {},
   "source": [
    "As we mentioned we have the 3 tables that we need to merge: medical records, physical exam, and the IQ tests. Let's quickly take a snapshots of them to see completeness and find out the primary and foreign keys: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "arranged-lease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95 entries, 0 to 94\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   passport_id       87 non-null     string\n",
      " 1   field_exam_score  92 non-null     Int64 \n",
      " 2   student_id        80 non-null     string\n",
      " 3   db_ID             95 non-null     object\n",
      "dtypes: Int64(1), object(1), string(2)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "deadly-playing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98 entries, 0 to 97\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   student_id  98 non-null     string\n",
      " 1   score       98 non-null     Int64 \n",
      " 2   db_ID       98 non-null     object\n",
      "dtypes: Int64(1), object(1), string(1)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_theo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "signal-therapist",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98 entries, 0 to 97\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   date_of_birth       98 non-null     datetime64[ns]\n",
      " 1   passport_id         98 non-null     string        \n",
      " 2   student_first_name  98 non-null     string        \n",
      " 3   student_last_name   98 non-null     string        \n",
      " 4   blood_type          98 non-null     string        \n",
      " 5   gender              98 non-null     string        \n",
      " 6   db_ID               98 non-null     object        \n",
      "dtypes: datetime64[ns](1), object(1), string(5)\n",
      "memory usage: 5.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_med.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-anaheim",
   "metadata": {},
   "source": [
    "Looks like the IQ exam is complete and everyone has taken the test. So we can try to add additional information to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "married-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113 entries, 0 to 112\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   student_id        98 non-null     string  \n",
      " 1   score             98 non-null     Int64   \n",
      " 2   db_ID_theo        98 non-null     object  \n",
      " 3   passport_id       87 non-null     string  \n",
      " 4   field_exam_score  92 non-null     Int64   \n",
      " 5   db_ID_pe          95 non-null     object  \n",
      " 6   merger            113 non-null    category\n",
      "dtypes: Int64(2), category(1), object(2), string(2)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# merge student\n",
    "\"\"\"The theo student table is complete and we merge it with the practical\"\"\"\n",
    "df_report = pd.merge(df_theo,\n",
    "                     df_pe,\n",
    "                     on='student_id',\n",
    "                     how='outer',\n",
    "                     suffixes=(\"_theo\",\"_pe\"),\n",
    "                    indicator='merger')\n",
    "df_report.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "passive-mexico",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merger\n",
       "both          80\n",
       "left_only     18\n",
       "right_only    15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.merger.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-timeline",
   "metadata": {},
   "source": [
    "No duplicates, but it seems a lot of the physical exam records were not merged. Well the only reason could be that the student IDs are missing or they are faulty. Doing an out join tells us if there are any issues with both tables. Left joins would be left for after the investigation process. Let's see what's going on in the right table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "fluid-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>field_exam_score</th>\n",
       "      <th>student_id</th>\n",
       "      <th>db_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I8987_x</td>\n",
       "      <td>12</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>PE_EXAM_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>65</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>PE_EXAM_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>66</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>PE_EXAM_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>79</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>PE_EXAM_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>94</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>PE_EXAM_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I161H6029</td>\n",
       "      <td>58</td>\n",
       "      <td>V42V13R33C</td>\n",
       "      <td>PE_EXAM_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Expired passport</td>\n",
       "      <td>11</td>\n",
       "      <td>A40E12X76K</td>\n",
       "      <td>PE_EXAM_92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>H104H6344</td>\n",
       "      <td>14</td>\n",
       "      <td>F96U81D87W</td>\n",
       "      <td>PE_EXAM_93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>67</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>PE_EXAM_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>88</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>PE_EXAM_95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passport_id  field_exam_score  student_id       db_ID\n",
       "0        F193I8987_x                12  O69K36F35N  PE_EXAM_01\n",
       "1          G213H6876                65        <NA>  PE_EXAM_02\n",
       "2          E122C7613                66  N95Q83K66L  PE_EXAM_03\n",
       "3          E236I5047                79  F23F98R36E  PE_EXAM_04\n",
       "4          I119I9824                94        <NA>  PE_EXAM_05\n",
       "..               ...               ...         ...         ...\n",
       "90         I161H6029                58  V42V13R33C  PE_EXAM_91\n",
       "91  Expired passport                11  A40E12X76K  PE_EXAM_92\n",
       "92         H104H6344                14  F96U81D87W  PE_EXAM_93\n",
       "93         I212A5244                67  G16E29S55N  PE_EXAM_94\n",
       "94         C161A7431                88  D34Q23Q41L  PE_EXAM_95\n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "abandoned-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>score</th>\n",
       "      <th>db_ID_theo</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>field_exam_score</th>\n",
       "      <th>db_ID_pe</th>\n",
       "      <th>merger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G213H6876</td>\n",
       "      <td>65</td>\n",
       "      <td>PE_EXAM_02</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I119I9824</td>\n",
       "      <td>94</td>\n",
       "      <td>PE_EXAM_05</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D195D9493</td>\n",
       "      <td>24</td>\n",
       "      <td>PE_EXAM_12</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D142I7007</td>\n",
       "      <td>48</td>\n",
       "      <td>PE_EXAM_19</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D161I6944</td>\n",
       "      <td>10</td>\n",
       "      <td>PE_EXAM_24</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G222G8347</td>\n",
       "      <td>76</td>\n",
       "      <td>PE_EXAM_28</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A158E6453</td>\n",
       "      <td>35</td>\n",
       "      <td>PE_EXAM_34</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H268D7080</td>\n",
       "      <td>91</td>\n",
       "      <td>PE_EXAM_37</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C140A6549</td>\n",
       "      <td>15</td>\n",
       "      <td>PE_EXAM_43</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A107E7669</td>\n",
       "      <td>79</td>\n",
       "      <td>PE_EXAM_50</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I113A7725</td>\n",
       "      <td>73</td>\n",
       "      <td>PE_EXAM_59</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E175A7258</td>\n",
       "      <td>84</td>\n",
       "      <td>PE_EXAM_67</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D114D5052</td>\n",
       "      <td>97</td>\n",
       "      <td>PE_EXAM_75</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I224H7974</td>\n",
       "      <td>39</td>\n",
       "      <td>PE_EXAM_81</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I148F8499</td>\n",
       "      <td>38</td>\n",
       "      <td>PE_EXAM_90</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id  score db_ID_theo passport_id  field_exam_score    db_ID_pe  \\\n",
       "98        <NA>   <NA>        NaN   G213H6876                65  PE_EXAM_02   \n",
       "99        <NA>   <NA>        NaN   I119I9824                94  PE_EXAM_05   \n",
       "100       <NA>   <NA>        NaN   D195D9493                24  PE_EXAM_12   \n",
       "101       <NA>   <NA>        NaN   D142I7007                48  PE_EXAM_19   \n",
       "102       <NA>   <NA>        NaN   D161I6944                10  PE_EXAM_24   \n",
       "103       <NA>   <NA>        NaN   G222G8347                76  PE_EXAM_28   \n",
       "104       <NA>   <NA>        NaN   A158E6453                35  PE_EXAM_34   \n",
       "105       <NA>   <NA>        NaN   H268D7080                91  PE_EXAM_37   \n",
       "106       <NA>   <NA>        NaN   C140A6549                15  PE_EXAM_43   \n",
       "107       <NA>   <NA>        NaN   A107E7669                79  PE_EXAM_50   \n",
       "108       <NA>   <NA>        NaN   I113A7725                73  PE_EXAM_59   \n",
       "109       <NA>   <NA>        NaN   E175A7258                84  PE_EXAM_67   \n",
       "110       <NA>   <NA>        NaN   D114D5052                97  PE_EXAM_75   \n",
       "111       <NA>   <NA>        NaN   I224H7974                39  PE_EXAM_81   \n",
       "112       <NA>   <NA>        NaN   I148F8499                38  PE_EXAM_90   \n",
       "\n",
       "         merger  \n",
       "98   right_only  \n",
       "99   right_only  \n",
       "100  right_only  \n",
       "101  right_only  \n",
       "102  right_only  \n",
       "103  right_only  \n",
       "104  right_only  \n",
       "105  right_only  \n",
       "106  right_only  \n",
       "107  right_only  \n",
       "108  right_only  \n",
       "109  right_only  \n",
       "110  right_only  \n",
       "111  right_only  \n",
       "112  right_only  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.query(\"merger =='right_only'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "particular-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>score</th>\n",
       "      <th>db_ID_theo</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>field_exam_score</th>\n",
       "      <th>db_ID_pe</th>\n",
       "      <th>merger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>58</td>\n",
       "      <td>THEO_EXAM_02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>73</td>\n",
       "      <td>THEO_EXAM_05</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U30F35G12E</td>\n",
       "      <td>61</td>\n",
       "      <td>THEO_EXAM_12</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A32J48B87E</td>\n",
       "      <td>35</td>\n",
       "      <td>THEO_EXAM_19</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Y64Z79C83L</td>\n",
       "      <td>65</td>\n",
       "      <td>THEO_EXAM_24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S85H92U16R</td>\n",
       "      <td>87</td>\n",
       "      <td>THEO_EXAM_28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Y68K44O33E</td>\n",
       "      <td>12</td>\n",
       "      <td>THEO_EXAM_31</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>T23W58G70E</td>\n",
       "      <td>60</td>\n",
       "      <td>THEO_EXAM_32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>K50V21E10E</td>\n",
       "      <td>86</td>\n",
       "      <td>THEO_EXAM_33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>K33F51P59O</td>\n",
       "      <td>46</td>\n",
       "      <td>THEO_EXAM_37</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>K42B47E15J</td>\n",
       "      <td>7</td>\n",
       "      <td>THEO_EXAM_40</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>L69B86K78X</td>\n",
       "      <td>60</td>\n",
       "      <td>THEO_EXAM_46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>H81O65A56M</td>\n",
       "      <td>36</td>\n",
       "      <td>THEO_EXAM_53</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>E71P34J57U</td>\n",
       "      <td>42</td>\n",
       "      <td>THEO_EXAM_62</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>C68J19X65S</td>\n",
       "      <td>77</td>\n",
       "      <td>THEO_EXAM_70</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>N16E91G49J</td>\n",
       "      <td>63</td>\n",
       "      <td>THEO_EXAM_78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Z77O99Y48B</td>\n",
       "      <td>22</td>\n",
       "      <td>THEO_EXAM_84</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>V56E38U67E</td>\n",
       "      <td>28</td>\n",
       "      <td>THEO_EXAM_93</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id  score    db_ID_theo passport_id  field_exam_score db_ID_pe  \\\n",
       "1   S67Y79P97N     58  THEO_EXAM_02        <NA>              <NA>      NaN   \n",
       "4   X84A95B48H     73  THEO_EXAM_05        <NA>              <NA>      NaN   \n",
       "11  U30F35G12E     61  THEO_EXAM_12        <NA>              <NA>      NaN   \n",
       "18  A32J48B87E     35  THEO_EXAM_19        <NA>              <NA>      NaN   \n",
       "23  Y64Z79C83L     65  THEO_EXAM_24        <NA>              <NA>      NaN   \n",
       "27  S85H92U16R     87  THEO_EXAM_28        <NA>              <NA>      NaN   \n",
       "30  Y68K44O33E     12  THEO_EXAM_31        <NA>              <NA>      NaN   \n",
       "31  T23W58G70E     60  THEO_EXAM_32        <NA>              <NA>      NaN   \n",
       "32  K50V21E10E     86  THEO_EXAM_33        <NA>              <NA>      NaN   \n",
       "36  K33F51P59O     46  THEO_EXAM_37        <NA>              <NA>      NaN   \n",
       "39  K42B47E15J      7  THEO_EXAM_40        <NA>              <NA>      NaN   \n",
       "45  L69B86K78X     60  THEO_EXAM_46        <NA>              <NA>      NaN   \n",
       "52  H81O65A56M     36  THEO_EXAM_53        <NA>              <NA>      NaN   \n",
       "61  E71P34J57U     42  THEO_EXAM_62        <NA>              <NA>      NaN   \n",
       "69  C68J19X65S     77  THEO_EXAM_70        <NA>              <NA>      NaN   \n",
       "77  N16E91G49J     63  THEO_EXAM_78        <NA>              <NA>      NaN   \n",
       "83  Z77O99Y48B     22  THEO_EXAM_84        <NA>              <NA>      NaN   \n",
       "92  V56E38U67E     28  THEO_EXAM_93        <NA>              <NA>      NaN   \n",
       "\n",
       "       merger  \n",
       "1   left_only  \n",
       "4   left_only  \n",
       "11  left_only  \n",
       "18  left_only  \n",
       "23  left_only  \n",
       "27  left_only  \n",
       "30  left_only  \n",
       "31  left_only  \n",
       "32  left_only  \n",
       "36  left_only  \n",
       "39  left_only  \n",
       "45  left_only  \n",
       "52  left_only  \n",
       "61  left_only  \n",
       "69  left_only  \n",
       "77  left_only  \n",
       "83  left_only  \n",
       "92  left_only  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.query(\"merger =='left_only'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-guyana",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Investigate the IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e5b33-1e34-4567-9b5a-5b2f0d841158",
   "metadata": {},
   "source": [
    "Let's check if the ids are complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-tenant",
   "metadata": {},
   "source": [
    "We can clearly see in the physical exam records that many students did not provide their student IDs, maybe they didn't do the same or there we typos. To improve the merge, we need to address this issue. \n",
    "\n",
    "As you have access to the HR database, you can request student IDs and passport IDs from the HR department. Upon calling the HR department, provide them with all the passport IDs and student IDs available and request additional student information such as names and academic levels. Since you already obtained passport consents from the physical exam, everyone is identifiable. In return, the HR department sends you the data.\n",
    "\n",
    "It's crucial to note that accessing data from other departments is not permissible without proper clearance. The delay in merging the data initially was due to the necessity to prove the absence of data and obtain appropriate permissions. \n",
    "\n",
    "In this project even though it is a simulation, if you are working in a highly regulated industry, data security is paramount, and you will face more issues like this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7a29a-0fd2-4002-96ca-95fd85f0282d",
   "metadata": {},
   "source": [
    "What is interesting is that the medical database has passport values which are complete and correct. The HR database has a complete set of data for all the students, this will help us to create a correct identification database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "productive-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I898722</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>Female</td>\n",
       "      <td>Refat</td>\n",
       "      <td>Natali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arianna</td>\n",
       "      <td>Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>Female</td>\n",
       "      <td>Inge</td>\n",
       "      <td>Bego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>Male</td>\n",
       "      <td>Alush</td>\n",
       "      <td>Bauyrzhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>Male</td>\n",
       "      <td>Luo+Ping</td>\n",
       "      <td>Palbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I161H6029</td>\n",
       "      <td>V42V13R33C</td>\n",
       "      <td>Female</td>\n",
       "      <td>Trini</td>\n",
       "      <td>Dong+Keun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>B205A8589</td>\n",
       "      <td>A40E12X76K</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lovise</td>\n",
       "      <td>Ji+Kui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>H104H6344</td>\n",
       "      <td>F96U81D87W</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ishilde</td>\n",
       "      <td>Jalldëz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>Female</td>\n",
       "      <td>Joselyne</td>\n",
       "      <td>Godi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lyndi</td>\n",
       "      <td>Muamir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    passport_id  student_id  gender first_name  last_name\n",
       "0   F193I898722  O69K36F35N  Female      Refat     Natali\n",
       "1     G213H6876  S67Y79P97N    Male    Arianna        Kim\n",
       "2     E122C7613  N95Q83K66L  Female       Inge       Bego\n",
       "3     E236I5047  F23F98R36E    Male      Alush  Bauyrzhan\n",
       "4     I119I9824  X84A95B48H    Male   Luo+Ping      Palbo\n",
       "..          ...         ...     ...        ...        ...\n",
       "93    I161H6029  V42V13R33C  Female      Trini  Dong+Keun\n",
       "94    B205A8589  A40E12X76K  Female     Lovise     Ji+Kui\n",
       "95    H104H6344  F96U81D87W  Female    Ishilde    Jalldëz\n",
       "96    I212A5244  G16E29S55N  Female   Joselyne       Godi\n",
       "97    C161A7431  D34Q23Q41L  Female      Lyndi     Muamir\n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge student \n",
    "\"\"\"The medical table can have passport ids we don't know about. Plus we have no access to it\"\"\"\n",
    "df_ids= pd.merge(df_hr, df_med,\n",
    "                  on='passport_id',\n",
    "                  how='outer',\n",
    "                  suffixes=(\"_hr\",'_med'))[['passport_id','student_id','gender','student_first_name_hr','student_last_name_hr']]\n",
    "df_ids.rename({'student_first_name_hr':'first_name','student_last_name_hr':'last_name'},axis=1,inplace=True)\n",
    "\n",
    "df_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658f9e2-70d1-460b-b651-b9a37462e391",
   "metadata": {},
   "source": [
    "Below is a function that will check the status of a dirty list of ids compared to a set of correct ones. This will help us to fix the ids of the database in interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "geographic-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: CLEAN -> IQ exam - student id\n",
      "[INFO]: MISSING (18)-> Physical exam - student id\n",
      "[INFO]: FIX (3)-> Physical exam - passports\n",
      "[INFO]: MISSING (18)-> Physical exam - passports\n",
      "[INFO]: MISSING (2)-> Fees - student id\n",
      "[INFO]: MISSING (2)-> Fees - passports\n"
     ]
    }
   ],
   "source": [
    "def id_checker(dirty_list, clean_list, name=None,missing_values=True):\n",
    "    \"\"\"\n",
    "    This function takes 2 lists and compares them. \n",
    "    It returns a dictionary which tells you will ids to fix and the ones that are missing. \n",
    "    \"\"\"\n",
    "    dirty_set = set(dirty_list)\n",
    "    clean_set = set(clean_list)\n",
    "    \n",
    "    fix = dirty_set - clean_set.intersection(dirty_set)\n",
    "    missing = clean_set - clean_set.intersection(dirty_set)\n",
    "    if missing_values:\n",
    "        res = {'fix':fix}\n",
    "        res = {'fix':fix,'missing':missing}\n",
    "        if len(fix) == 0 and len(missing)==0: print(f\"[INFO]: CLEAN -> {name}\")\n",
    "        if len(fix) != 0: print(f\"[INFO]: FIX ({len(fix)})-> {name}\")\n",
    "        if len(missing)!=0: print(f\"[INFO]: MISSING ({len(missing)})-> {name}\") \n",
    "    else: \n",
    "        res = {'fix':fix,'missing':missing}\n",
    "        if len(fix) == 0 and len(missing)==0: print(f\"[INFO]: CLEAN -> {name}\")\n",
    "        if len(fix) != 0: print(f\"[INFO]: FIX ({len(fix)})-> {name}\")\n",
    "\n",
    "    return res    \n",
    "        \n",
    "# For the theoretical\n",
    "theo_ids = id_checker(df_theo.student_id.dropna(),df_ids.student_id,'IQ exam - student id')\n",
    "prac_ids = id_checker(df_pe.student_id.dropna(),df_ids.student_id,'Physical exam - student id')\n",
    "prac_pass = id_checker(df_pe.passport_id.dropna(),df_ids.passport_id,'Physical exam - passports')\n",
    "fee_ids = id_checker(df_fee.student_id.dropna(),df_ids.student_id,'Fees - student id')\n",
    "fee_pass = id_checker(df_fee.passport_id.dropna(),df_ids.passport_id,'Fees - passports')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "prompt-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fix': set(), 'missing': {'Z84Y31Z35Q', 'Z97G71Y84S'}}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fee_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "excellent-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fix': {'<N/A>', 'Expired passport', 'F193I8987_x'},\n",
       " 'missing': {'A114C7641',\n",
       "  'A165E9973',\n",
       "  'A286D8586',\n",
       "  'B205A8589',\n",
       "  'C180A9432',\n",
       "  'C277F5942',\n",
       "  'D172B8726',\n",
       "  'D174I8785',\n",
       "  'D176B7482',\n",
       "  'E282F5666',\n",
       "  'F193I898722',\n",
       "  'F202B6991',\n",
       "  'F242E6691',\n",
       "  'G123C6077',\n",
       "  'G226B9008',\n",
       "  'G237G5382',\n",
       "  'G263C6339',\n",
       "  'G288H6343'}}"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prac_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-childhood",
   "metadata": {},
   "source": [
    "Sometimes even different issues can occure. Look at the fees database. It shows that there are no errors. The IDs are correct but we having missing student informations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "objective-shooting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>tuition_fees</th>\n",
       "      <th>semester</th>\n",
       "      <th>loan</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>db_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192.0</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>192.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>B165I8646</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>FEES_177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>165</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.177083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722.666667</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56.826915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.367369</td>\n",
       "      <td>0.501307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>98.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>146.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>852.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>997.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        transaction_id  student_id passport_id  tuition_fees  semester  loan  \\\n",
       "count            192.0         175         176         192.0     192.0   192   \n",
       "unique            <NA>          96          96          <NA>      <NA>     2   \n",
       "top               <NA>  S67Y79P97N   B165I8646          <NA>      <NA>  True   \n",
       "freq              <NA>           2           2          <NA>      <NA>   165   \n",
       "mean         98.177083         NaN         NaN    722.666667       1.5   NaN   \n",
       "std          56.826915         NaN         NaN    149.367369  0.501307   NaN   \n",
       "min                1.0         NaN         NaN         503.0       1.0   NaN   \n",
       "25%              48.75         NaN         NaN         585.0       1.0   NaN   \n",
       "50%               98.5         NaN         NaN         702.0       1.5   NaN   \n",
       "75%             146.25         NaN         NaN        852.25       2.0   NaN   \n",
       "max              196.0         NaN         NaN         997.0       2.0   NaN   \n",
       "\n",
       "       scholarship     db_ID  \n",
       "count          192       192  \n",
       "unique           2       192  \n",
       "top          False  FEES_177  \n",
       "freq           184         1  \n",
       "mean           NaN       NaN  \n",
       "std            NaN       NaN  \n",
       "min            NaN       NaN  \n",
       "25%            NaN       NaN  \n",
       "50%            NaN       NaN  \n",
       "75%            NaN       NaN  \n",
       "max            NaN       NaN  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fee.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd96b21-7e59-4190-9f92-b8e387fae8be",
   "metadata": {},
   "source": [
    "The fees database has multiple transaction information, so we need to aggregate it to get a final clean usable database, where each student will have a summary about themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "governing-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>tuition_fees</th>\n",
       "      <th>db_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>N46D16J18G</td>\n",
       "      <td>G236C7367</td>\n",
       "      <td>1470</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>N16E91G49J</td>\n",
       "      <td>D114D5052</td>\n",
       "      <td>1449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>M61K98C62H</td>\n",
       "      <td>C277F5942</td>\n",
       "      <td>1218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>M19B87Z20V</td>\n",
       "      <td>D288G5298</td>\n",
       "      <td>1489</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>W83C28W43D</td>\n",
       "      <td>A135H7268</td>\n",
       "      <td>1646</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>K33F51P59O</td>\n",
       "      <td>A158E6453</td>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>H81O65A56M</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>H81O65A56M</td>\n",
       "      <td>A107E7669</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>G38B13O78Q</td>\n",
       "      <td>G194I7411</td>\n",
       "      <td>972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>N41U97V40B</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id passport_id  tuition_fees  db_ID\n",
       "59  N46D16J18G   G236C7367          1470      2\n",
       "56  N16E91G49J   D114D5052          1449      2\n",
       "54  M61K98C62H   C277F5942          1218      2\n",
       "53  M19B87Z20V   D288G5298          1489      2\n",
       "96  W83C28W43D   A135H7268          1646      2\n",
       "..         ...         ...           ...    ...\n",
       "41  K33F51P59O   A158E6453           592      1\n",
       "39  H81O65A56M        <NA>           890      1\n",
       "38  H81O65A56M   A107E7669           576      1\n",
       "35  G38B13O78Q   G194I7411           972      1\n",
       "58  N41U97V40B        <NA>           961      1\n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = df_fee.groupby([\"student_id\",'passport_id'],dropna=False).agg({'tuition_fees':'sum','db_ID':'count'}).reset_index()\n",
    "summary.sort_values(\"db_ID\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-cattle",
   "metadata": {},
   "source": [
    "The database is composed of 2 semesters worth of payments and in some cases students either didn't supply their student ID or the passport. And since the IDs are complete what we can do here is use the database itself to cross enrich between the 2 IDs and as a result we can get a unified aggregated tuition fees table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "restricted-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_map = {}\n",
    "pass_map = {}\n",
    "for st_id, pass_id in zip(summary.student_id,summary.passport_id):\n",
    "    if pd.isna(st_id) or pd.isna(pass_id): pass\n",
    "    else: \n",
    "        st_map[st_id] = pass_id\n",
    "        pass_map[pass_id] = st_id \n",
    "        \n",
    "\n",
    "df_fee['student_id_clean'] = df_fee.passport_id.map(pass_map).fillna(df_fee['student_id'])\n",
    "df_fee['passport_id_clean'] = df_fee.student_id.map(st_map).fillna(df_fee['passport_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-montgomery",
   "metadata": {},
   "source": [
    "**You have to fix for the other columns since the previous dates caused issues for those qualitative ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "unusual-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id_clean</th>\n",
       "      <th>passport_id_clean</th>\n",
       "      <th>tuition_fees</th>\n",
       "      <th>loan</th>\n",
       "      <th>scholarship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Y68K44O33E</td>\n",
       "      <td>A165E9973</td>\n",
       "      <td>1194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Y64Z79C83L</td>\n",
       "      <td>D161I6944</td>\n",
       "      <td>1238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Y49Y11T74M</td>\n",
       "      <td>G288H6343</td>\n",
       "      <td>1648</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>I119I9824</td>\n",
       "      <td>1631</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>S85H92U16R</td>\n",
       "      <td>G222G8347</td>\n",
       "      <td>1797</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>I212A5244</td>\n",
       "      <td>1616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F96U81D87W</td>\n",
       "      <td>H104H6344</td>\n",
       "      <td>1459</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>F74B39J14J</td>\n",
       "      <td>C134B8514</td>\n",
       "      <td>1403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>F29F90D95Y</td>\n",
       "      <td>H238H6612</td>\n",
       "      <td>1765</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>K42B47E15J</td>\n",
       "      <td>H268D7080</td>\n",
       "      <td>1405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id_clean passport_id_clean  tuition_fees  loan  scholarship\n",
       "89       Y68K44O33E         A165E9973          1194     0            1\n",
       "88       Y64Z79C83L         D161I6944          1238     0            1\n",
       "87       Y49Y11T74M         G288H6343          1648     0            1\n",
       "86       X84A95B48H         I119I9824          1631     0            1\n",
       "68       S85H92U16R         G222G8347          1797     1            0\n",
       "..              ...               ...           ...   ...          ...\n",
       "27       G16E29S55N         I212A5244          1616     1            0\n",
       "26       F96U81D87W         H104H6344          1459     1            0\n",
       "25       F74B39J14J         C134B8514          1403     1            0\n",
       "24       F29F90D95Y         H238H6612          1765     1            0\n",
       "35       K42B47E15J         H268D7080          1405     1            0\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = df_fee.groupby([\"student_id_clean\",'passport_id_clean']).agg({'tuition_fees':'sum','loan':'sum','scholarship':'sum'}).reset_index()\n",
    "summary.loc[summary.loan==0,'loan'] = 0\n",
    "summary.loc[summary.loan!=0,'loan'] = 1\n",
    "summary.loc[summary.scholarship==0,'scholarship'] = 0\n",
    "summary.loc[summary.scholarship!=0,'scholarship'] = 1\n",
    "\n",
    "summary.sort_values(\"scholarship\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "sonic-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fee_clean = summary.copy().rename({\"student_id_clean\":\"student_id\",\"passport_id_clean\":'passport_id'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-algorithm",
   "metadata": {},
   "source": [
    "Seems like the guys who have a scholarship are getting fundings from some external organization. Let's see what happened to those 2 missing students from the HR file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "bottom-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: MISSING (2)-> Fees - student id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fix': set(), 'missing': {'Z84Y31Z35Q', 'Z97G71Y84S'}}"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fee_ids = id_checker(df_fee_clean.student_id.dropna(),df_ids.student_id,'Fees - student id')\n",
    "fee_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "extensive-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fee_ids['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "proof-treat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>scholarship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Z84Y31Z35Q</td>\n",
       "      <td>F212E6749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Z97G71Y84S</td>\n",
       "      <td>H292E6722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id passport_id  scholarship\n",
       "60  Z84Y31Z35Q   F212E6749            1\n",
       "68  Z97G71Y84S   H292E6722            1"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss = df_hr.query(\"student_id in @temp\")\n",
    "df_miss[['student_id','passport_id','scholarship']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-administrator",
   "metadata": {},
   "source": [
    "Oh look at that! They have scholarships! Must be they have an agreement with the university itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "abandoned-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fee_final= pd.concat([df_fee_clean,df_miss[['student_id','passport_id','scholarship']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "married-theta",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>tuition_fees</th>\n",
       "      <th>loan</th>\n",
       "      <th>scholarship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A23J68Q95Z</td>\n",
       "      <td>D176B7482</td>\n",
       "      <td>1739</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26D49U61M</td>\n",
       "      <td>B165I8646</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A30W79B50M</td>\n",
       "      <td>H214E7302</td>\n",
       "      <td>1372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A32J48B87E</td>\n",
       "      <td>D142I7007</td>\n",
       "      <td>1074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A38U71K78K</td>\n",
       "      <td>B207I9427</td>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Z24D47P30W</td>\n",
       "      <td>D144I7429</td>\n",
       "      <td>1521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Z75S49G13B</td>\n",
       "      <td>G240A8482</td>\n",
       "      <td>1719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Z77O99Y48B</td>\n",
       "      <td>I224H7974</td>\n",
       "      <td>1892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Z84Y31Z35Q</td>\n",
       "      <td>F212E6749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Z97G71Y84S</td>\n",
       "      <td>H292E6722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id passport_id  tuition_fees  loan  scholarship\n",
       "0   A23J68Q95Z   D176B7482          1739     1            0\n",
       "1   A26D49U61M   B165I8646          1717     1            0\n",
       "2   A30W79B50M   H214E7302          1372     1            0\n",
       "3   A32J48B87E   D142I7007          1074     1            0\n",
       "4   A38U71K78K   B207I9427          1073     1            0\n",
       "..         ...         ...           ...   ...          ...\n",
       "93  Z24D47P30W   D144I7429          1521     0            0\n",
       "94  Z75S49G13B   G240A8482          1719     0            0\n",
       "95  Z77O99Y48B   I224H7974          1892     1            0\n",
       "60  Z84Y31Z35Q   F212E6749             0     0            1\n",
       "68  Z97G71Y84S   H292E6722             0     0            1\n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fee_final.fillna(0,inplace=True)\n",
    "df_fee_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-settle",
   "metadata": {},
   "source": [
    "#### Cleaning the tables fo  \n",
    "\n",
    "Now that we understand the mechanism, let create a function which will do this enrichment for us\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad09397",
   "metadata": {},
   "source": [
    "Be carefull that some of the values have a NA nature or some flags which say the need to be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "involved-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ids(df_dirty,\n",
    "            df_clean, \n",
    "            id_col_pairs,\n",
    "            replacement = ['<N/A>', 'Expired passport']):\n",
    "    \n",
    "    # Replace the replacements with NaN\n",
    "    df_use = df_dirty.copy().replace({i:np.nan for i in replacement})\n",
    "\n",
    "    for id_col in id_col_pairs:\n",
    "        dirty_id_list = df_use[id_col].replace({i:np.nan for i in replacement}).dropna().tolist()\n",
    "        clean_id_list = df_clean[id_col].replace({i:np.nan for i in replacement}).dropna().tolist()\n",
    "\n",
    "        # 1st check\n",
    "        check = id_checker(dirty_id_list,clean_id_list,id_col,missing_values=False)\n",
    "\n",
    "\n",
    "        #Apply a fuzzy match if possible \n",
    "        if len(check['fix'])!=0:\n",
    "            fix_map = {}\n",
    "            for bad_id in list(check['fix']):\n",
    "                nearest_string, _ = fw_process.extractOne(str(bad_id), clean_id_list)\n",
    "                fix_map[bad_id] = nearest_string    \n",
    "\n",
    "            df_use[id_col].replace(fix_map,inplace=True)   \n",
    "            \n",
    "        \n",
    "        \n",
    "    #impute by cross matching\n",
    "    cross_mapping = df_clean.dropna().set_index(id_col_pairs[0])[id_col_pairs[1]].to_dict()\n",
    "    df_use[id_col_pairs[1]].fillna(df_use[id_col_pairs[0]].map(cross_mapping),inplace=True)\n",
    "    \n",
    "    #impute by cross matching\n",
    "    cross_mapping = df_clean.dropna().set_index(id_col_pairs[1])[id_col_pairs[0]].to_dict()\n",
    "    df_use[id_col_pairs[0]].fillna(df_use[id_col_pairs[1]].map(cross_mapping),inplace=True)\n",
    "    \n",
    "\n",
    "    return df_use\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "8344f79b-f4f5-472b-86be-cd5c93ec2c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: FIX (1)-> passport_id\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_pe_final = fix_ids(clean_db['PE_EXAM']['db'], df_ids, ['student_id','passport_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "4865564f-6a3b-47d5-ae19-44546d0776e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>field_exam_score</th>\n",
       "      <th>student_id</th>\n",
       "      <th>db_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I898722</td>\n",
       "      <td>12</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>PE_EXAM_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>65</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>PE_EXAM_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>66</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>PE_EXAM_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>79</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>PE_EXAM_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>94</td>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>PE_EXAM_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I161H6029</td>\n",
       "      <td>58</td>\n",
       "      <td>V42V13R33C</td>\n",
       "      <td>PE_EXAM_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>B205A8589</td>\n",
       "      <td>11</td>\n",
       "      <td>A40E12X76K</td>\n",
       "      <td>PE_EXAM_92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>H104H6344</td>\n",
       "      <td>14</td>\n",
       "      <td>F96U81D87W</td>\n",
       "      <td>PE_EXAM_93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>67</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>PE_EXAM_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>88</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>PE_EXAM_95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    passport_id  field_exam_score  student_id       db_ID\n",
       "0   F193I898722                12  O69K36F35N  PE_EXAM_01\n",
       "1     G213H6876                65  S67Y79P97N  PE_EXAM_02\n",
       "2     E122C7613                66  N95Q83K66L  PE_EXAM_03\n",
       "3     E236I5047                79  F23F98R36E  PE_EXAM_04\n",
       "4     I119I9824                94  X84A95B48H  PE_EXAM_05\n",
       "..          ...               ...         ...         ...\n",
       "90    I161H6029                58  V42V13R33C  PE_EXAM_91\n",
       "91    B205A8589                11  A40E12X76K  PE_EXAM_92\n",
       "92    H104H6344                14  F96U81D87W  PE_EXAM_93\n",
       "93    I212A5244                67  G16E29S55N  PE_EXAM_94\n",
       "94    C161A7431                88  D34Q23Q41L  PE_EXAM_95\n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "551adddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_president = pd.merge(df_pe_final,\n",
    "                        df_theo,\n",
    "                         on=['student_id'],\n",
    "                         how='outer',\n",
    "                         suffixes=(\"_pe\",\"_theo\")).rename({\"field_exam_score\":'PE_score','score':'IQ_score'},axis=1).drop(['db_ID_theo','db_ID_pe'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "280d98bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: CLEAN -> student_id\n"
     ]
    }
   ],
   "source": [
    "df_president = fix_ids(df_president, df_ids, ['student_id','passport_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "decc79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>PE_score</th>\n",
       "      <th>IQ_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I898722</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>88</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A165E9973</td>\n",
       "      <td>Y68K44O33E</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>G123C6077</td>\n",
       "      <td>T23W58G70E</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>F202B6991</td>\n",
       "      <td>K50V21E10E</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    passport_id  student_id  PE_score  IQ_score\n",
       "0   F193I898722  O69K36F35N        12        71\n",
       "1     G213H6876  S67Y79P97N        65        58\n",
       "2     E122C7613  N95Q83K66L        66        88\n",
       "3     E236I5047  F23F98R36E        79        69\n",
       "4     I119I9824  X84A95B48H        94        73\n",
       "..          ...         ...       ...       ...\n",
       "93    I212A5244  G16E29S55N        67        74\n",
       "94    C161A7431  D34Q23Q41L        88        47\n",
       "95    A165E9973  Y68K44O33E      <NA>        12\n",
       "96    G123C6077  T23W58G70E      <NA>        60\n",
       "97    F202B6991  K50V21E10E      <NA>        86\n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_president[['passport_id','student_id','PE_score','IQ_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73300518-8bcf-4ad4-abf1-1f2701cd3bec",
   "metadata": {},
   "source": [
    "Let's wrap up the data\n",
    "- Student identifier -> Done \n",
    "- Name and last name of the student -> To be added\n",
    "- Age of the student -> to be calculated\n",
    "- Educational major -> to be added \n",
    "- Academic seniority (which year the student is in) -> to be added \n",
    "- Gender -> to be added \n",
    "- Blood type -> To be added \n",
    "- Grades of the physical exam -> Done \n",
    "- Grades of the theoretical/IQ exam -> Done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "184ebb13-fe07-4f04-891c-4109a72217d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['enrollment_date', 'date_of_birth', 'passport_id', 'email',\n",
       "       'student_id', 'student_first_name', 'student_last_name',\n",
       "       'seniortiy_description', 'major', 'scholarship', 'db_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "e4816aad-fdc7-4082-bc64-6f42e181ede9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_president = pd.merge(df_president,df_hr,on=['student_id','passport_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a4453e5b-7120-44ba-bb70-52f36f087080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_first_name</th>\n",
       "      <th>student_last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>PE_score</th>\n",
       "      <th>IQ_score</th>\n",
       "      <th>major</th>\n",
       "      <th>seniortiy_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I898722</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>Refat</td>\n",
       "      <td>Natali</td>\n",
       "      <td>1994-08-08</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Freshman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>Arianna</td>\n",
       "      <td>Kim</td>\n",
       "      <td>1994-06-14</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Sophmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>Inge</td>\n",
       "      <td>Bego</td>\n",
       "      <td>1993-03-05</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>Alush</td>\n",
       "      <td>Bauyrzhan</td>\n",
       "      <td>1995-11-27</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Sophmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>Luo+Ping</td>\n",
       "      <td>Palbo</td>\n",
       "      <td>1993-12-28</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Sophmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>Joselyne</td>\n",
       "      <td>Godi</td>\n",
       "      <td>1993-06-17</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Freshman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>Lyndi</td>\n",
       "      <td>Muamir</td>\n",
       "      <td>1995-02-16</td>\n",
       "      <td>88</td>\n",
       "      <td>47</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Sophmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A165E9973</td>\n",
       "      <td>Y68K44O33E</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Fawzi</td>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>12</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Freshman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>G123C6077</td>\n",
       "      <td>T23W58G70E</td>\n",
       "      <td>Stefanino</td>\n",
       "      <td>Chedva</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>F202B6991</td>\n",
       "      <td>K50V21E10E</td>\n",
       "      <td>Elmars</td>\n",
       "      <td>Nidaa</td>\n",
       "      <td>1994-09-13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>86</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Freshman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    passport_id  student_id student_first_name student_last_name  \\\n",
       "0   F193I898722  O69K36F35N              Refat            Natali   \n",
       "1     G213H6876  S67Y79P97N            Arianna               Kim   \n",
       "2     E122C7613  N95Q83K66L               Inge              Bego   \n",
       "3     E236I5047  F23F98R36E              Alush         Bauyrzhan   \n",
       "4     I119I9824  X84A95B48H           Luo+Ping             Palbo   \n",
       "..          ...         ...                ...               ...   \n",
       "93    I212A5244  G16E29S55N           Joselyne              Godi   \n",
       "94    C161A7431  D34Q23Q41L              Lyndi            Muamir   \n",
       "95    A165E9973  Y68K44O33E           Danielle             Fawzi   \n",
       "96    G123C6077  T23W58G70E          Stefanino            Chedva   \n",
       "97    F202B6991  K50V21E10E             Elmars             Nidaa   \n",
       "\n",
       "   date_of_birth  PE_score  IQ_score                  major  \\\n",
       "0     1994-08-08        12        71      Civil Engineering   \n",
       "1     1994-06-14        65        58      Civil Engineering   \n",
       "2     1993-03-05        66        88   Chemical Engineering   \n",
       "3     1995-11-27        79        69       Computer Science   \n",
       "4     1993-12-28        94        73      Civil Engineering   \n",
       "..           ...       ...       ...                    ...   \n",
       "93    1993-06-17        67        74           Biochemistry   \n",
       "94    1995-02-16        88        47                Biology   \n",
       "95    1995-01-15      <NA>        12  Environmental Science   \n",
       "96    1993-02-01      <NA>        60  Environmental Science   \n",
       "97    1994-09-13      <NA>        86            Mathematics   \n",
       "\n",
       "   seniortiy_description  \n",
       "0               Freshman  \n",
       "1               Sophmore  \n",
       "2                 Senior  \n",
       "3               Sophmore  \n",
       "4               Sophmore  \n",
       "..                   ...  \n",
       "93              Freshman  \n",
       "94              Sophmore  \n",
       "95              Freshman  \n",
       "96                Senior  \n",
       "97              Freshman  \n",
       "\n",
       "[98 rows x 9 columns]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_president = df_president[['passport_id','student_id','student_first_name','student_last_name','date_of_birth','PE_score','IQ_score','major','seniortiy_description']]\n",
    "df_president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "74314dbd-4d6c-494b-a26b-995bbea13f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_first_name</th>\n",
       "      <th>student_last_name</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>db_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994-08-08</td>\n",
       "      <td>F193I898722</td>\n",
       "      <td>Refat</td>\n",
       "      <td>Natali</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994-06-14</td>\n",
       "      <td>G213H6876</td>\n",
       "      <td>Arianna</td>\n",
       "      <td>Kim</td>\n",
       "      <td>A-</td>\n",
       "      <td>Male</td>\n",
       "      <td>MEDICAL_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-03-05</td>\n",
       "      <td>E122C7613</td>\n",
       "      <td>Inge</td>\n",
       "      <td>Bego</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-11-27</td>\n",
       "      <td>E236I5047</td>\n",
       "      <td>Alush</td>\n",
       "      <td>Bauyrzhan</td>\n",
       "      <td>A+</td>\n",
       "      <td>Male</td>\n",
       "      <td>MEDICAL_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-12-28</td>\n",
       "      <td>I119I9824</td>\n",
       "      <td>Luo+Ping</td>\n",
       "      <td>Palbo</td>\n",
       "      <td>O-</td>\n",
       "      <td>Male</td>\n",
       "      <td>MEDICAL_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1995-11-28</td>\n",
       "      <td>I161H6029</td>\n",
       "      <td>Trini</td>\n",
       "      <td>Dong+Keun</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1993-03-28</td>\n",
       "      <td>B205A8589</td>\n",
       "      <td>Lovise</td>\n",
       "      <td>Ji+Kui</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1995-03-27</td>\n",
       "      <td>H104H6344</td>\n",
       "      <td>Ishilde</td>\n",
       "      <td>Jalldëz</td>\n",
       "      <td>B+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1993-06-17</td>\n",
       "      <td>I212A5244</td>\n",
       "      <td>Joselyne</td>\n",
       "      <td>Godi</td>\n",
       "      <td>B-</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1995-02-16</td>\n",
       "      <td>C161A7431</td>\n",
       "      <td>Lyndi</td>\n",
       "      <td>Muamir</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEDICAL_98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_of_birth  passport_id student_first_name student_last_name blood_type  \\\n",
       "0     1994-08-08  F193I898722              Refat            Natali         O+   \n",
       "1     1994-06-14    G213H6876            Arianna               Kim         A-   \n",
       "2     1993-03-05    E122C7613               Inge              Bego         O+   \n",
       "3     1995-11-27    E236I5047              Alush         Bauyrzhan         A+   \n",
       "4     1993-12-28    I119I9824           Luo+Ping             Palbo         O-   \n",
       "..           ...          ...                ...               ...        ...   \n",
       "93    1995-11-28    I161H6029              Trini         Dong+Keun        AB+   \n",
       "94    1993-03-28    B205A8589             Lovise            Ji+Kui        AB+   \n",
       "95    1995-03-27    H104H6344            Ishilde           Jalldëz         B+   \n",
       "96    1993-06-17    I212A5244           Joselyne              Godi         B-   \n",
       "97    1995-02-16    C161A7431              Lyndi            Muamir         O+   \n",
       "\n",
       "    gender       db_ID  \n",
       "0   Female  MEDICAL_01  \n",
       "1     Male  MEDICAL_02  \n",
       "2   Female  MEDICAL_03  \n",
       "3     Male  MEDICAL_04  \n",
       "4     Male  MEDICAL_05  \n",
       "..     ...         ...  \n",
       "93  Female  MEDICAL_94  \n",
       "94  Female  MEDICAL_95  \n",
       "95  Female  MEDICAL_96  \n",
       "96  Female  MEDICAL_97  \n",
       "97  Female  MEDICAL_98  \n",
       "\n",
       "[98 rows x 7 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "90f9bdf7-de81-4ae3-ac71-9c34c2d7c021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_president = pd.merge(df_president,df_med[['passport_id','blood_type','gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "341da1c0-8e56-423d-886c-6d0530008aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_date = datetime.date.today()\n",
    "df_president['Age'] = np.round((date_parser.parse(current_date.strftime(\"%d-%m-%Y\"))- df_president['date_of_birth']).dt.days/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "de502178-fbcd-4880-9513-056f53dcfe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_first_name</th>\n",
       "      <th>student_last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>PE_score</th>\n",
       "      <th>IQ_score</th>\n",
       "      <th>major</th>\n",
       "      <th>seniortiy_description</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>E277A9345</td>\n",
       "      <td>U43X69O71Q</td>\n",
       "      <td>Ína</td>\n",
       "      <td>Amédé</td>\n",
       "      <td>1995-10-12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>O-</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>H292E6722</td>\n",
       "      <td>Z97G71Y84S</td>\n",
       "      <td>Shi+Liang</td>\n",
       "      <td>Magnþóra</td>\n",
       "      <td>1994-04-05</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>B-</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>C236F6011</td>\n",
       "      <td>F24U56Y56Y</td>\n",
       "      <td>Chien+Min</td>\n",
       "      <td>Irfan</td>\n",
       "      <td>1994-12-24</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>B-</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>F237I6757</td>\n",
       "      <td>J85O89G46H</td>\n",
       "      <td>Fachtna</td>\n",
       "      <td>Seo</td>\n",
       "      <td>1994-01-22</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>H268D7080</td>\n",
       "      <td>K42B47E15J</td>\n",
       "      <td>Su+Chen</td>\n",
       "      <td>Elve</td>\n",
       "      <td>1993-09-06</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>O+</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C195F5934</td>\n",
       "      <td>N95K98P24K</td>\n",
       "      <td>Friedlind</td>\n",
       "      <td>Snævar</td>\n",
       "      <td>1994-07-16</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>E222C5387</td>\n",
       "      <td>C41L29D24E</td>\n",
       "      <td>Maksym</td>\n",
       "      <td>Alexej</td>\n",
       "      <td>1993-02-16</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>A-</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I229G8627</td>\n",
       "      <td>H52N33P76Z</td>\n",
       "      <td>Ihno</td>\n",
       "      <td>Ekke</td>\n",
       "      <td>1993-08-17</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>F212E6749</td>\n",
       "      <td>Z84Y31Z35Q</td>\n",
       "      <td>Eunice</td>\n",
       "      <td>So Hwan</td>\n",
       "      <td>1993-03-07</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>B-</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B103D5597</td>\n",
       "      <td>K87X34O34F</td>\n",
       "      <td>Kati</td>\n",
       "      <td>Gerd</td>\n",
       "      <td>1993-01-11</td>\n",
       "      <td>36</td>\n",
       "      <td>99</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>O-</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   passport_id  student_id student_first_name student_last_name date_of_birth  \\\n",
       "85   E277A9345  U43X69O71Q                Ína             Amédé    1995-10-12   \n",
       "65   H292E6722  Z97G71Y84S          Shi+Liang          Magnþóra    1994-04-05   \n",
       "68   C236F6011  F24U56Y56Y          Chien+Min             Irfan    1994-12-24   \n",
       "60   F237I6757  J85O89G46H            Fachtna               Seo    1994-01-22   \n",
       "36   H268D7080  K42B47E15J            Su+Chen              Elve    1993-09-06   \n",
       "..         ...         ...                ...               ...           ...   \n",
       "9    C195F5934  N95K98P24K          Friedlind            Snævar    1994-07-16   \n",
       "45   E222C5387  C41L29D24E             Maksym            Alexej    1993-02-16   \n",
       "22   I229G8627  H52N33P76Z               Ihno              Ekke    1993-08-17   \n",
       "57   F212E6749  Z84Y31Z35Q             Eunice           So Hwan    1993-03-07   \n",
       "76   B103D5597  K87X34O34F               Kati              Gerd    1993-01-11   \n",
       "\n",
       "    PE_score  IQ_score                   major seniortiy_description  \\\n",
       "85         8         2             Mathematics              Freshman   \n",
       "65        64         2            Biochemistry              Sophmore   \n",
       "68        88         6                 Biology              Freshman   \n",
       "60        23         6  Mechanical Engineering              Freshman   \n",
       "36        91         7  Electrical Engineering              Freshman   \n",
       "..       ...       ...                     ...                   ...   \n",
       "9         80        92   Environmental Science              Sophmore   \n",
       "45        25        94            Biochemistry              Freshman   \n",
       "22        78        97                 Physics              Freshman   \n",
       "57         9        99             Mathematics              Sophmore   \n",
       "76        36        99  Mechanical Engineering              Sophmore   \n",
       "\n",
       "   blood_type  gender   Age  \n",
       "85         O-  Female  28.0  \n",
       "65         B-    Male  30.0  \n",
       "68         B-  Female  29.0  \n",
       "60        AB+  Female  30.0  \n",
       "36         O+    Male  30.0  \n",
       "..        ...     ...   ...  \n",
       "9         AB-    Male  30.0  \n",
       "45         A-  Female  31.0  \n",
       "22        AB-    Male  31.0  \n",
       "57         B-    Male  31.0  \n",
       "76         O-    Male  31.0  \n",
       "\n",
       "[98 rows x 12 columns]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_president.sort_values(\"IQ_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "aef6934a-e08a-4ce1-85fe-c0ee45c66468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_president = pd.merge(df_president,df_fee_final,on='student_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "55c025c1-3941-4b28-a6cb-0061d5bbc45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passport_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_first_name</th>\n",
       "      <th>student_last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>PE_score</th>\n",
       "      <th>IQ_score</th>\n",
       "      <th>major</th>\n",
       "      <th>seniortiy_description</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>tuition_fees</th>\n",
       "      <th>loan</th>\n",
       "      <th>scholarship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F193I898722</td>\n",
       "      <td>O69K36F35N</td>\n",
       "      <td>Refat</td>\n",
       "      <td>Natali</td>\n",
       "      <td>1994-08-08</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G213H6876</td>\n",
       "      <td>S67Y79P97N</td>\n",
       "      <td>Arianna</td>\n",
       "      <td>Kim</td>\n",
       "      <td>1994-06-14</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>A-</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E122C7613</td>\n",
       "      <td>N95Q83K66L</td>\n",
       "      <td>Inge</td>\n",
       "      <td>Bego</td>\n",
       "      <td>1993-03-05</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>Chemical Engineering</td>\n",
       "      <td>Senior</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E236I5047</td>\n",
       "      <td>F23F98R36E</td>\n",
       "      <td>Alush</td>\n",
       "      <td>Bauyrzhan</td>\n",
       "      <td>1995-11-27</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>A+</td>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I119I9824</td>\n",
       "      <td>X84A95B48H</td>\n",
       "      <td>Luo+Ping</td>\n",
       "      <td>Palbo</td>\n",
       "      <td>1993-12-28</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>O-</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I212A5244</td>\n",
       "      <td>G16E29S55N</td>\n",
       "      <td>Joselyne</td>\n",
       "      <td>Godi</td>\n",
       "      <td>1993-06-17</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>B-</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C161A7431</td>\n",
       "      <td>D34Q23Q41L</td>\n",
       "      <td>Lyndi</td>\n",
       "      <td>Muamir</td>\n",
       "      <td>1995-02-16</td>\n",
       "      <td>88</td>\n",
       "      <td>47</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Sophmore</td>\n",
       "      <td>O+</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A165E9973</td>\n",
       "      <td>Y68K44O33E</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Fawzi</td>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>12</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>B-</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>G123C6077</td>\n",
       "      <td>T23W58G70E</td>\n",
       "      <td>Stefanino</td>\n",
       "      <td>Chedva</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Senior</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>F202B6991</td>\n",
       "      <td>K50V21E10E</td>\n",
       "      <td>Elmars</td>\n",
       "      <td>Nidaa</td>\n",
       "      <td>1994-09-13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>86</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    passport_id  student_id student_first_name student_last_name  \\\n",
       "0   F193I898722  O69K36F35N              Refat            Natali   \n",
       "1     G213H6876  S67Y79P97N            Arianna               Kim   \n",
       "2     E122C7613  N95Q83K66L               Inge              Bego   \n",
       "3     E236I5047  F23F98R36E              Alush         Bauyrzhan   \n",
       "4     I119I9824  X84A95B48H           Luo+Ping             Palbo   \n",
       "..          ...         ...                ...               ...   \n",
       "93    I212A5244  G16E29S55N           Joselyne              Godi   \n",
       "94    C161A7431  D34Q23Q41L              Lyndi            Muamir   \n",
       "95    A165E9973  Y68K44O33E           Danielle             Fawzi   \n",
       "96    G123C6077  T23W58G70E          Stefanino            Chedva   \n",
       "97    F202B6991  K50V21E10E             Elmars             Nidaa   \n",
       "\n",
       "   date_of_birth  PE_score  IQ_score                  major  \\\n",
       "0     1994-08-08        12        71      Civil Engineering   \n",
       "1     1994-06-14        65        58      Civil Engineering   \n",
       "2     1993-03-05        66        88   Chemical Engineering   \n",
       "3     1995-11-27        79        69       Computer Science   \n",
       "4     1993-12-28        94        73      Civil Engineering   \n",
       "..           ...       ...       ...                    ...   \n",
       "93    1993-06-17        67        74           Biochemistry   \n",
       "94    1995-02-16        88        47                Biology   \n",
       "95    1995-01-15      <NA>        12  Environmental Science   \n",
       "96    1993-02-01      <NA>        60  Environmental Science   \n",
       "97    1994-09-13      <NA>        86            Mathematics   \n",
       "\n",
       "   seniortiy_description blood_type  gender   Age  tuition_fees  loan  \\\n",
       "0               Freshman         O+  Female  30.0          1522     1   \n",
       "1               Sophmore         A-    Male  30.0          1468     1   \n",
       "2                 Senior         O+  Female  31.0          1626     1   \n",
       "3               Sophmore         A+    Male  28.0          1779     1   \n",
       "4               Sophmore         O-    Male  30.0          1631     0   \n",
       "..                   ...        ...     ...   ...           ...   ...   \n",
       "93              Freshman         B-  Female  31.0          1616     1   \n",
       "94              Sophmore         O+  Female  29.0          1690     1   \n",
       "95              Freshman         B-    Male  29.0          1194     0   \n",
       "96                Senior        AB+    Male  31.0          1433     1   \n",
       "97              Freshman        AB-    Male  29.0          1600     1   \n",
       "\n",
       "    scholarship  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "..          ...  \n",
       "93            0  \n",
       "94            0  \n",
       "95            1  \n",
       "96            0  \n",
       "97            0  \n",
       "\n",
       "[98 rows x 15 columns]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_president"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43066f46-ffb4-48ec-b624-95312b20cde5",
   "metadata": {},
   "source": [
    "Now the data science starts ... From garbage to reusable raw data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cc7e4c-4604-4ba0-bd56-7ea53726d622",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc860ac6-5c26-4b59-b16d-6b21199d5ed0",
   "metadata": {},
   "source": [
    "We have taken a simulation of a university data and worked to understand its componenets, we analyzed and made sure the data is complete and imputed the data based on existing data from other tables where the values are similar and connected. Without any predictive analytics or assumptions.\n",
    "\n",
    "The things we did included:\n",
    "1. Standardizing the data\n",
    "2. Optimizing the format and data types\n",
    "3. Cleaning the databases\n",
    "4. Imputing missing ID\n",
    "5. Merging tables\n",
    "\n",
    "All of this is part of a data engieer's arsenal, such as querying relational databases and setting up a pipeline which ensures the other data teams and domain experts will be able to use the data in an efficient way, knowing the databases are complete and usebale to help them make descisions and predict what they need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedbd2f-35bf-4534-8260-77d3c12be743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
